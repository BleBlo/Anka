
================================================================================
TITLE
================================================================================

Teaching LLMs Domain-Specific Languages via Prompt:
Anka, a DSL for Reliable Data Transformation Pipelines

================================================================================
ABSTRACT
================================================================================

We investigate whether Large Language Models can effectively learn and
generate code in a novel domain-specific language (DSL) taught entirely
via in-context prompting. We introduce Anka, a constrained DSL for data
transformations designed to reduce common LLM coding errors through
explicit, step-by-step syntax.

Despite having zero prior training exposure to Anka, Claude 3.5 Haiku
achieves 99.9% parse success and 95.8% overall accuracy across 80
benchmark tasks spanning data filtering, mapping, aggregation, and
multi-step pipelines. Critically, Anka demonstrates a 40% accuracy
advantage over Python on multi-step pipeline tasks (100% vs 60%),
where Python's flexible syntax leads to frequent errors in operation
sequencing and variable management.

Our results demonstrate that: (1) LLMs can learn novel DSLs entirely
from prompts, achieving near-native accuracy; (2) constrained syntax
significantly reduces errors on complex, multi-step tasks; and
(3) domain-specific languages designed for LLM generation can outperform
general-purpose languages even when the LLM has extensive training on
the latter.

Anka compiles to multiple targets (Python/pandas, SQL, Apache Spark),
enabling verified LLM-generated code to execute in production
environments. We release the complete language implementation,
benchmark suite, and evaluation framework.

================================================================================
KEYWORDS
================================================================================

Large Language Models, Domain-Specific Languages, Code Generation,
Data Transformation, Prompt Engineering, LLM Evaluation

================================================================================
